import numpy as np
import gym
from dreamer.envs.wrapper import EnvWrapper
from rlpyt.spaces.float_box import FloatBox

class NormalizeActions(EnvWrapper):

    def __init__(self, env):
        super().__init__(env)
        self._mask = np.logical_and(
            np.isfinite(env.action_space.low),
            np.isfinite(env.action_space.high))
        self._low = np.where(self._mask, env.action_space.low, -1)
        self._high = np.where(self._mask, env.action_space.high, 1)

    @property
    def action_space(self):
        low = np.where(self._mask, -np.ones_like(self._low), self._low)
        high = np.where(self._mask, np.ones_like(self._low), self._high)
        return FloatBox(low, high, dtype=np.float32)

    def step(self, action):
        original = (action + 1) / 2 * (self._high - self._low) + self._low
        original = np.where(self._mask, original, action)
        return self.env.step(original)

    def reset(self):
        # reset any initialized vars?
        print("NORMALIZE ACTIONS RESET")
        return self.env.reset()
