<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>SharedWorldModels</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Dreamer</h1>
        <p>Shared World Models</p>
        <p class="view"><a href="http://github.com/deepdad/SharedWorldModels">View the Project on GitHub <small>orderedlist/minimal</small></a></p>
        <ul>
          <li><a href="https://github.com/deepdad/SharedWorldModels/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/deepdad/SharedWorldModels/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="http://github.com/deepdad/SharedWorldModels">Fork On <strong>GitHub</strong></a></li>
        </ul>
        <p><a href="#experiments">Experiments</a></p>
        <p><a href="#dynamics">Dynamics</a></p>
        <p><a href="#latent_imagination">Latent Imagination</a></p>
        <p><a href="#reparameterization">Reparameterization</a></p>
        <p><a href="#rssm">RSSM</a></p>
        <p><a href="#imagination_horizon">Imagination Horizon</a></p>
        <p><a href="#analytic_gradients">Analytic Gradients</a></p>
      </header>
      <section>
        <h1>Dreamer V1</h1>

        <p><em>View the <a href="http://github.github.com/github-flavored-markdown/sample_content.html">source of this content</a>.</em></p>

        <p>The goal of this article is to clarify the papers <a href="https://arxiv.org/pdf/1912.01603.pdf" title="dreamer-v1">Dream to 
          Control: Learning Behaviors by Latent Imagination</a> and ... </p>
        
        <p>In the first paper, the authors repeatedly write <blockquote><p>backpropagate through the neural
          network dynamics</blockquote></p> or variants of that. I found that an unclear choice of words. 
          Especially on the first reading. Because you 
          don't backpropagate through neural network dynamics, do you? You simply backpropagate gradients 
          through a neural network. So what do they mean?</p> 
        <p>Well, as it turns out, just explaining that phrase, explains a lot of the paper and the paper
          can be explained by explaining that phrase, touching
          on everything in the paper. Which is what I will try to do in this article.</p>
        <p>And you might expect an IPython notebook here. But notebooks mainly run through
          source code, while here I try to run through the paper and clarify some things. 
          Some of these things are references to external sources, 
          some things are probably basic for many readers but may not be active knowledge for others. 
          In the explanation here, I also have a few pointers
          into the source code, which is fairly concise. It won't help us achieve our main mission, 
          which is to change ‘dm_control‘ to ‘RLBench‘ so this
          article doesn't have priority, but it will hopefully help getting started with the source code.
        </p>  

        <div id="dynamics">
           <h2>Dynamics</h2>
        </div>
       <p>In sum, "leveraging the neural network latent dynamics" is what it is.</p>


        <div id="experiments">
           <h2>Experiments</h2>
        </div>
       <p>The sparse reward didn't seem to produce the desired results. We implemented a dense reward.
          This experiment uses it, with one 64camera, gcloud, TargetReach.</p>
       <a href="https://tensorboard.dev/experiment/gNNiou9gSDOYoMWG2njUxg/#scalars" title="experiment1">Experiment1</a>


       <div id="latent_imagination">
           <h2>Latent Imagination</h2>
       </div>
       <p>Then we have:
       <ul>  
         <li><blockquote><p>latent imagination<p><blockquote></li>
         <li><blockquote><p>hypothetical trajectories in the compact latent space of the world model<p><blockquote></li>
       </ul>
       These are synonymous. And, given the lack of imagery, also a poor choice of words. Rollout would be better or "forward pass."
       "Latent imagination" is a phrase mainly used in the title. You might as well ignore it.
       </p>


       <div id="reparameterization">
           <h2>Reparameterization</h2>
       </div>
       <p>To understand this aspect of Dreamer, I paraphrase Bengio et al. Traditional neural networks implement a deterministic transformation of some input 
          variables <b>x</b>. 


       <div id="rssm">
           <h2>RSSM</h2>
       </div>
       <p>Planet, people, profit</p>
       <p>At Google, we put PlaNet first, a neural network. It comes before the people we intend to replace, brainwash or mollify. Leading to profit.</p>


       <div id="imagination_horizon">
           <h2>Imagination Horizon</h2>
       </div>


       <div id="analytic_gradients">
           <h2>Analytic Gradients</h2>
       </div>



          
        
       
        <div id="imagination_horizon">
           <h2>IMAGINATION HORIZON</h2>
        </div>
          <pre><code>&lt;div class="footer"&gt;
    &amp;copy; 2004 Foo Corporation
&lt;/div&gt;
</code></pre>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/deepdad">Sam</a> and <a  href="https://github.com/Wetzr">Joe</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
